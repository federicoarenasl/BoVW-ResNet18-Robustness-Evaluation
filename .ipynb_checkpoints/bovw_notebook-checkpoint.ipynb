{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dated-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library import\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-windsor",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "better-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_splits_df(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    splits_train = []\n",
    "    splits_val = []\n",
    "\n",
    "    divs = ['C', 'B', 'A']\n",
    "\n",
    "    for div in divs:\n",
    "        # Create training set for current split\n",
    "        train_df = shuffle(df.loc[df.folder != div], random_state=0)\n",
    "        splits_train.append(train_df[['image_id', 'label']]) # folder column is removed\n",
    "        # Create validation set for current split\n",
    "        val_df = shuffle(df.loc[df.folder == div], random_state=0)\n",
    "        splits_val.append(val_df[['image_id', 'label']]) # folder column is removed\n",
    "\n",
    "    return splits_train, splits_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "official-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_reader(dataframe):\n",
    "    image_dict = {}\n",
    "    file_locations = list(dataframe['image_id'])\n",
    "    labels = list(dataframe['label'])\n",
    "    category_0 = []\n",
    "    category_1 = []\n",
    "    for i in range(len(file_locations)):\n",
    "        image = cv2.imread(file_locations[i], cv2.COLOR_RGB2BGR)\n",
    "        try:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        except: # if the image is gray\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        if labels[i] == 0:\n",
    "            category_0.append(image)\n",
    "        else:\n",
    "            category_1.append(image)\n",
    "\n",
    "    image_dict['0'] = category_0\n",
    "    image_dict['1'] = category_1\n",
    "\n",
    "    return image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "functional-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates descriptors using sift \n",
    "# Takes one parameter that is images dictionary\n",
    "# Return an array whose first index holds the decriptor_list without an order\n",
    "# And the second index holds the sift_vectors dictionary which holds the descriptors but this is seperated class by class\n",
    "def sift_features(images):\n",
    "    sift_vectors = {}\n",
    "    descriptor_list = []\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    for key,value in images.items():\n",
    "        features = []\n",
    "        for img in value:\n",
    "            kp, des = sift.detectAndCompute(img,None)\n",
    "           \n",
    "            descriptor_list.extend(des)\n",
    "            features.append(des)\n",
    "        sift_vectors[key] = features\n",
    "    return [descriptor_list, sift_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "german-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A k-means clustering algorithm who takes 2 parameter which is number \n",
    "# of cluster(k) and the other is descriptors list(unordered 1d array)\n",
    "# Returns an array that holds central points.\n",
    "def kmeans(k, descriptor_list):\n",
    "    kmeans = KMeans(n_clusters = k, n_init=1, verbose=1)\n",
    "    kmeans.fit(descriptor_list)\n",
    "    visual_words = kmeans.cluster_centers_ \n",
    "    labels = kmeans.labels_\n",
    "    return visual_words, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-classic",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "received-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to dictionary of images\n",
    "train_splits, val_splits = csv_to_splits_df(\"catdogs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "broken-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get split 1 data\n",
    "split_index = 0\n",
    "train_dict = image_reader(train_splits[split_index])\n",
    "val_dict = image_reader(val_splits[split_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "explicit-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full sift features for training data\n",
    "sifts = sift_features(train_dict) \n",
    "# Takes the descriptor list which is unordered one\n",
    "descriptor_list = sifts[0] \n",
    "# Takes the sift features that is seperated class by class for train data\n",
    "all_bovw_feature = sifts[1] \n",
    "# Takes the sift features that is seperated class by class for test data\n",
    "test_bovw_feature = sift_features(val_dict)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "caroline-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the central points which is visual words\n",
    "# visual_words, labels = kmeans(150, descriptor_list) \n",
    "# np.save('visual_words.npy', visual_words)\n",
    "# np.save('labels.npy', labels)\n",
    "visual_words = np.load('visual_words.npy')\n",
    "labels = np.load('labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "narrow-border",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62.94211344, 64.36363636, 21.8003108 , ..., 11.27117327,\n",
       "        12.17521368, 14.35780886],\n",
       "       [19.02210339, 19.20285205, 13.66524064, ..., 11.03386809,\n",
       "        12.90730838, 16.85383244],\n",
       "       [15.40208173, 13.81071704, 15.31881264, ..., 12.91634541,\n",
       "        17.42868157, 17.28103315],\n",
       "       ...,\n",
       "       [15.63968958, 10.13192905, 11.07612712, ...,  4.92461197,\n",
       "         8.37952698, 14.38211382],\n",
       "       [43.51051525, 17.27076761,  6.66403785, ..., 16.33569926,\n",
       "         5.9161409 ,  9.37329127],\n",
       "       [18.39364084, 14.38826691, 12.56739812, ...,  5.06627855,\n",
       "         3.39274519,  4.91177788]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-prairie",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
