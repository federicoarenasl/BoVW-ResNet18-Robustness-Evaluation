{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Bag of Visual Words implementation for Dog and Cat detection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Library import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/mnt/c/Users/Federico Arenas/Documents/Federico/UoE/MSC_AI/2021-1/IVC/Coursework/IVC_project\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "source": [
    "## Helper functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Convert dataframe to dictionary of images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset of data split\n",
    "def get_splits(split_n):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    path = './data/split_'+str(split_n)+'/split_'+str(split_n)+\"_\"\n",
    "    train_df = pd.read_csv(path+'train.csv')\n",
    "    val_df = pd.read_csv(path+'val.csv')\n",
    "\n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Convert dataframe to dictionary of images\n"
     ]
    }
   ],
   "source": [
    "print('Convert dataframe to dictionary of images')\n",
    "split_n = 1\n",
    "train_splits, val_splits = get_splits(split_n)"
   ]
  },
  {
   "source": [
    "## Get split of data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and store images\n",
    "def image_reader(dataframe):\n",
    "    '''\n",
    "    '''\n",
    "    image_dict = {}\n",
    "    file_locations = list(dataframe['image_id'])\n",
    "    labels = list(dataframe['label'])\n",
    "    category_0 = []\n",
    "    category_1 = []\n",
    "    for i in range(len(file_locations)):\n",
    "        image = cv2.imread(file_locations[i], cv2.COLOR_RGB2BGR)\n",
    "        try:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        except: # if the image is gray\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        if labels[i] == 0:\n",
    "            category_0.append(image)\n",
    "        else:\n",
    "            category_1.append(image)\n",
    "\n",
    "    image_dict[0] = category_0\n",
    "    image_dict[1] = category_1\n",
    "\n",
    "    return image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Get split 1 data\n"
     ]
    }
   ],
   "source": [
    "# Get split 1 data\n",
    "print('Get split 1 data')\n",
    "train_dict = image_reader(train_splits)\n",
    "val_dict = image_reader(val_splits)"
   ]
  },
  {
   "source": [
    "## Get full sift features for training data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SIFT features and descriptors\n",
    "def sift_features(images):\n",
    "    '''\n",
    "    Creates descriptors using sift. Takes one parameter that is images dictionary. Return an array whose first \n",
    "    index holds the decriptor_list without an order and the second index holds the sift_vectors dictionary which\n",
    "    holds the descriptors but this is seperated class by class.\n",
    "    '''\n",
    "    sift_vectors = {}\n",
    "    descriptor_list = []\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    for key,value in tqdm(images.items()):\n",
    "        features = []\n",
    "        for img in tqdm(value):\n",
    "            kp, des = sift.detectAndCompute(img,None)\n",
    "            descriptor_list.extend(des)\n",
    "            features.append(des)\n",
    "        sift_vectors[key] = features\n",
    "\n",
    "    return descriptor_list, sift_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Get full sift features for training data\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b35b83bce8e477287a8b8b69ba0e21d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/792 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a90de72400c408194fc446b0b8a0992"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/800 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09021429790e4f578009f66418f65e68"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Get full sift features for validation data...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f76ec42f6dbe4dfa847787ee0a5c90d4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/396 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c57e3513c8f46028867c6f126d4aad1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/400 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef5f20a563bc4b0797eba5fafdf99615"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "print('Get full sift features for training data')\n",
    "train_descriptor_list, train_sift_vectors = sift_features(train_dict)\n",
    "print('Get full sift features for validation data...')\n",
    "val_descriptor_list, val_sift_vectors = sift_features(val_dict)\n",
    "#np.save('output/bovw/sift_vectors.npy', sift_vectors)"
   ]
  },
  {
   "source": [
    "## Perform kmeans training to get visual words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform kmeans clustering on descriptors\n",
    "def kmeans(k, descriptor_list):\n",
    "    '''\n",
    "    A k-means clustering algorithm who takes 2 parameter which is number \n",
    "    of cluster(k) and the other is descriptors list(unordered 1d array)\n",
    "    Returns an array that holds central points.\n",
    "    '''\n",
    "    kmeans = KMeans(n_clusters = k, n_init=10, verbose=0)\n",
    "    kmeans.fit(descriptor_list)\n",
    "    vwords = kmeans.cluster_centers_\n",
    "\n",
    "    return kmeans, vwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Perform clustering on training data...\n",
      "Perform clustering on validation data...\n"
     ]
    }
   ],
   "source": [
    "# Perform kmeans training to get visual words\n",
    "K = 200\n",
    "print('Perform clustering on training data...')\n",
    "train_k_means, train_centers = kmeans(K, train_descriptor_list)\n",
    "print('Perform clustering on validation data...')\n",
    "val_k_means, valid_centers = kmeans(K, val_descriptor_list)"
   ]
  },
  {
   "source": [
    "## Get histograms from kmeans clustering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find index helper function\n",
    "def find_index(image, center):\n",
    "    count = 0\n",
    "    ind = 0\n",
    "    for i in range(len(center)):\n",
    "        if(i == 0):\n",
    "           count = distance.euclidean(image, center[i]) \n",
    "        else:\n",
    "            dist = distance.euclidean(image, center[i]) \n",
    "            if(dist < count):\n",
    "                ind = i\n",
    "                count = dist\n",
    "    return ind\n",
    "\n",
    "# Extract visual words from descriptors  \n",
    "def get_histograms_dictio(sift_vectors, kmeans_centers):\n",
    "    '''\n",
    "    '''    \n",
    "    dict_feature = {}\n",
    "    for key,value in sift_vectors.items():\n",
    "        print(f\"Getting histograms of class {key}...\")\n",
    "        category = []\n",
    "        for img in tqdm(value):\n",
    "            histogram = np.zeros(len(kmeans_centers))\n",
    "            for each_feature in img:\n",
    "                ind = find_index(each_feature, kmeans_centers)\n",
    "                histogram[ind] += 1\n",
    "            category.append(histogram)\n",
    "        dict_feature[key] = category\n",
    "    return dict_feature\n",
    "\n",
    "# Map dictionary of histograms to np arrays\n",
    "def get_histogram_arrays(sift_vectors, kmeans_centers):\n",
    "    histogram_dictio = get_histograms_dictio(sift_vectors, kmeans_centers)\n",
    "    X = []\n",
    "    Y = []\n",
    "    print(\"Converting to np.arrays...\")\n",
    "    for key in histogram_dictio.keys():\n",
    "        for value in tqdm(histogram_dictio[key]):\n",
    "            X.append(value)\n",
    "            Y.append(key)\n",
    "    \n",
    "    return np.array(X), np.array(Y)\n",
    "\n"
   ]
  },
  {
   "source": [
    "print(\"Get histograms from kmeans clustering\")\n",
    "train_histograms, train_classes = get_histogram_arrays(train_sift_vectors, train_centers)\n",
    "np.save('output/bovw/train_visual_words.npy', train_histograms)\n",
    "np.save('output/bovw/train_classes.npy', train_classes)\n",
    "print(\"Get validation histograms from kmeans clustering\")\n",
    "val_histograms, val_classes = get_histogram_arrays(val_sift_vectors, valid_centers)\n",
    "np.save('output/bovw/val_visual_words.npy', val_histograms)\n",
    "np.save('output/bovw/val_classes.npy', val_classes)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Get histograms from kmeans clustering\nGetting histograms of class 0...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/792 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ce89a59090d4dc0b3c423e81dbf8ad3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Getting histograms of class 1...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/800 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5d53d9449364b47b155781ca4175074"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converting to np.arrays...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/792 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9d6e105fcf4404ca28709ee14efdd65"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/800 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3cd820c179a456d9c39c5b0d6e0017c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Get validation histograms from kmeans clustering\nGetting histograms of class 0...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/396 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a7a2b71317c4ccf8d4fc4fc69125655"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Getting histograms of class 1...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/400 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57d9ff91ba744e02ae4df3dd46024678"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converting to np.arrays...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/396 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff459cbef5e942738392096f3698a4c8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/400 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ec9f90a2a4243d2a2eb201334dd542e"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "source": [
    "## Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_train_histograms = np.load('output/bovw/train_visual_words.npy')\n",
    "loaded_train_classes = np.load('output/bovw/train_classes.npy')\n",
    "loaded_val_histograms = np.load('output/bovw/val_visual_words.npy')\n",
    "loaded_val_classes = np.load('output/bovw/val_classes.npy')"
   ]
  },
  {
   "source": [
    "## Prepare SVM Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVM classifier\n",
    "def train_svm(visual_words, labels, c, kernel):\n",
    "    # Get training data\n",
    "    X_train = visual_words\n",
    "    Y_train = labels\n",
    "\n",
    "    # Initialize SVM classifier\n",
    "    svc_classifier = SVC(C=c, kernel=kernel, gamma=\"auto\")\n",
    "    svc_classifier.fit(X_train, Y_train)\n",
    "    \n",
    "    return svc_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train SVM classifier\n",
      "---\tC: 2;\tKernel: poly\t---\n",
      "\tTraining accuracy:\t 0.9755025125628141\n",
      "\tValidation accuracy:\t 0.49748743718592964\n",
      "---\tC: 2;\tKernel: rbf\t---\n",
      "\tTraining accuracy:\t 0.992462311557789\n",
      "\tValidation accuracy:\t 0.4962311557788945\n"
     ]
    }
   ],
   "source": [
    "# Train SVM classifier\n",
    "print(\"Train SVM classifier\")\n",
    "c_values = [2] #, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9]\n",
    "kernels = ['poly', 'rbf']\n",
    "for c in c_values:\n",
    "    for kernel in kernels:\n",
    "        svm_classifier = train_svm(train_histograms, train_classes, c, kernel)\n",
    "        print(\"---\\tC: {};\\tKernel: {}\\t---\".format(c, kernel))\n",
    "        print(\"\\tTraining accuracy:\\t\", svm_classifier.score(train_histograms, train_classes))\n",
    "        print(\"\\tValidation accuracy:\\t\", svm_classifier.score(val_histograms, val_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}